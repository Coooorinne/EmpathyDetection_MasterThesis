{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1Sak4TTHLBW6",
        "ZT8neBd-Lnzo",
        "2CGzfVpWPzKM"
      ],
      "toc_visible": true,
      "mount_file_id": "1Rd_rPvSoDSU3EW5B7RtXlJy3KhForE9-",
      "authorship_tag": "ABX9TyMPPv8QCXi4Ug/hhhlUO/+d"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N581bKAYsI3",
        "colab_type": "text"
      },
      "source": [
        "**LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGSQt1ZKYw_L",
        "colab_type": "text"
      },
      "source": [
        "Set-Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-Jy21Y7FCPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Only do once\n",
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "!cd fastText\n",
        "!sudo pip install fastText"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giaq23gNEfGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing modules\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn import metrics\n",
        "nltk.download('stopwords') #Downloading stopwords\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Bidirectional, Dense, TimeDistributed\n",
        "from tensorflow.keras.layers import Embedding, Flatten\n",
        "from tensorflow.keras.layers import MaxPooling1D, Dropout, Activation, Conv1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_zS76lAE71x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading dataset\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Data/dataset_groupedempathylevel.csv\")\n",
        "df.drop(df[df['length']<=3].index, inplace = True)  #droping all rows that are smaller/equal 3 in length\n",
        "columns_to_keep = ['text','classID', 'f_4', 'f_5'] #dropping the rest\n",
        "df = df[columns_to_keep]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4CniXxXFudm",
        "colab_type": "text"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YdDK4OEFl4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['text'] = df['text'].str.replace(r\"[\\d\\.]+\", \"\").str.strip() #Removing digits\n",
        "df['text'] = df['text'].str.replace(\"[^\\w\\s]\", \"\").str.lower() #Converting to lower case\n",
        "german_stop_words = nltk.corpus.stopwords.words('german') #List of german stopwords\n",
        "df['text'] = df['text'].apply(lambda x: ' '.join([item for item in x.split() if item not in german_stop_words])) #Removing stop words\n",
        "\n",
        "# Converting categorical labels to numerical values\n",
        "df[\"fn_4\"] = df[\"f_4\"].astype('category').cat.codes\n",
        "df[\"fn_5\"] = df[\"f_5\"].astype('category').cat.codes\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqOlA-CHGNWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initializing parameters\n",
        "CURR_PATH = !pwd\n",
        "PATH_DATA = CURR_PATH[0]\n",
        "PATH_MODELS = PATH_DATA + \"/content/drive/My Drive/Data/LSTM/saved models\"\n",
        "PATH_CHECKPOINTS = PATH_MODELS + \"checkpoints/\"\n",
        "\n",
        "MAX_FEATURES = 9358\n",
        "EMBED_DIM = 300\n",
        "MAXLEN = 302\n",
        "\n",
        "#Training\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey-_C2l9GUkA",
        "colab_type": "text"
      },
      "source": [
        "Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvWCj_eLGRcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(df, random_state=1, test_size=0.10, shuffle=True)\n",
        "X_train = np.array(train[\"text\"])\n",
        "Y_train_f4 = np.array(train[\"fn_4\"]).reshape((-1, 1))\n",
        "Y_train_f5 = np.array(train[\"fn_5\"]).reshape((-1, 1))\n",
        "X_test = np.array(test[\"text\"])\n",
        "Y_test_f4 = np.array(test[\"fn_4\"]).reshape((-1, 1))\n",
        "Y_test_f5 = np.array(test[\"fn_5\"]).reshape((-1, 1))\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrsbQrsqar7m",
        "colab_type": "text"
      },
      "source": [
        "Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8C6qwS1GYu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#OneHotEncoding\n",
        "Y_train_f4 = to_categorical(Y_train_f4)\n",
        "Y_test_f4 = to_categorical(Y_test_f4)\n",
        "Y_train_f5 = to_categorical(Y_train_f5)\n",
        "Y_test_f5 = to_categorical(Y_test_f5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EGNGlWQGkFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be9fb03b-22dc-47bb-cf22-859c70018190"
      },
      "source": [
        "#Text to list of indices representing words in dict\n",
        "tokenizer = Tokenizer(lower=True, split=\" \", num_words=MAX_FEATURES)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_vec = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_vec = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "MAXLEN = max([len(x) for x in X_train_vec])\n",
        "print(f\"Max vector length: {MAXLEN}\")\n",
        "\n",
        "# pad with zeros for same vector length\n",
        "X_train_vec = sequence.pad_sequences(X_train_vec, maxlen=MAXLEN, padding=\"post\")\n",
        "X_test_vec = sequence.pad_sequences(X_test_vec, maxlen=MAXLEN, padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max vector length: 302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpCCOmdEGw5x",
        "colab_type": "text"
      },
      "source": [
        "FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXGFIgwcGplh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Do onyl once\n",
        "from gensim.models import KeyedVectors\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vbzPDucG0MC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Do only once\n",
        "!wget \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.de.300.vec.gz\"\n",
        "!gzip -d cc.de.300.vec.gz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Wdi-XJG8Ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Do only once\n",
        "# Load Fasttext vector embeddings \n",
        "de_model = KeyedVectors.load_word2vec_format( \"cc.de.300.vec\")\n",
        "# use pickle to dump loaded model\n",
        "pickle.dump(de_model, open(\"/de_model.pkl\", \"wb\"))\n",
        "de_model = pickle.load(open(\"/de_model.pkl\", \"rb\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbmOw8t2HeDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading pickle model\n",
        "de_model = pickle.load(open(\"/de_model.pkl\", \"rb\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBnHDFgLHs4c",
        "colab_type": "text"
      },
      "source": [
        "Embedding Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShGv1LIbHril",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_not_found = []\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(MAX_FEATURES, len(word_index)) +1\n",
        "# define matrix dimensions\n",
        "embedding_matrix = np.zeros((nb_words, EMBED_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    try:\n",
        "        embedding_vector = de_model.get_vector(word)\n",
        "    except KeyError:\n",
        "        embedding_vector = None\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        words_not_found.append(word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sak4TTHLBW6",
        "colab_type": "text"
      },
      "source": [
        "# Model f_4 (emotional empathy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG-oKJ0HKr_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model architecture\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "model_f4 = Sequential()\n",
        "model_f4.add(\n",
        "    Embedding(\n",
        "        input_dim=nb_words,\n",
        "        output_dim=EMBED_DIM,\n",
        "        input_length=MAXLEN,\n",
        "        weights=[embedding_matrix],\n",
        "        trainable=True,\n",
        "    )\n",
        ")\n",
        "model_f4.add(LSTM (300,return_sequences=True,dropout=0.80)) \n",
        "model_f4.add(Dense(30,activation='tanh'))\n",
        "model_f4.add(Flatten())\n",
        "model_f4.add(Dense(20,activation='relu'))\n",
        "model_f4.add(Dense(4,activation='softmax'))\n",
        "model_f4.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),#RMSprop(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model_f4.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMLIugETLJ_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training f_4 Model\n",
        "\n",
        "%%time\n",
        "#Stop training when validation acc starts dropping and save checkpoint of model each period\n",
        "now = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
        "#create callbacks\n",
        "callbacks = [\n",
        "             EarlyStopping(monitor=\"val_loss\", verbose=1, patience=2),\n",
        "             ModelCheckpoint(\n",
        "                             PATH_CHECKPOINTS + now + \"_Model_FT-Embed_{epoch:02d}_{val_loss:.4f}.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             save_best_only=True,\n",
        "                             verbose=1,\n",
        "                             ),\n",
        "             ]\n",
        "\n",
        "#Fitting the model\n",
        "steps_per_epoch = int(np.floor((len(X_train_vec) / BATCH_SIZE)))\n",
        "print(\n",
        "      f\"Model Params.\\nbatch_size: {BATCH_SIZE}\\nEpochs: {EPOCHS}\\n\"\n",
        "      f\"Step p. Epoch: {steps_per_epoch}\\n\"\n",
        "      )\n",
        "\n",
        "hist = model_f4.fit(\n",
        "                    X_train_vec,\n",
        "                    Y_train_f4,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    callbacks=callbacks,\n",
        "                    validation_data=(X_test_vec, Y_test_f4),\n",
        "                    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sAr02cTLU2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluation f_4\n",
        "pred = model_f4.predict(X_train_vec)\n",
        "print('Accuracy of f_4 model on Training set')\n",
        "print(accuracy_score(Y_train_f4.argmax(axis=1), pred.argmax(axis=1)))\n",
        "print()\n",
        "\n",
        "# Predict on test data\n",
        "pred = model_f4.predict(X_test_vec)\n",
        "\n",
        "# Show prediction metrics\n",
        "print('Accuracy of f_4 model on Test set')\n",
        "print(accuracy_score(Y_test_f4.argmax(axis=1), pred.argmax(axis=1)))\n",
        "print()\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(Y_test_f4.argmax(axis=1), pred.argmax(axis=1)))\n",
        "print()\n",
        "print('Classification Report')\n",
        "report = metrics.classification_report(Y_test_f4.argmax(axis=1), pred.argmax(axis=1))\n",
        "print(report)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCZ-OIDK8dqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the model\n",
        "model_f4.save('/content/drive/My Drive/Data/LSTM/saved models/emotionalempathy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT8neBd-Lnzo",
        "colab_type": "text"
      },
      "source": [
        "# Model f_5 (cognitive empathy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgs_Uda4LYLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model architecture\n",
        "\n",
        "model_f5 = Sequential()\n",
        "model_f5.add(\n",
        "    Embedding(\n",
        "        input_dim=nb_words,\n",
        "        output_dim=EMBED_DIM,\n",
        "        input_length=MAXLEN,\n",
        "        weights=[embedding_matrix],\n",
        "        trainable=True,\n",
        "    )\n",
        ")\n",
        "\n",
        "model_f5.add(LSTM (300,return_sequences=True,dropout=0.80)) \n",
        "model_f5.add(Dense(30,activation='tanh'))\n",
        "model_f5.add(Flatten())\n",
        "model_f5.add(Dense(20,activation='relu'))\n",
        "model_f5.add(Dense(4,activation='softmax'))\n",
        "model_f5.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),#RMSprop(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model_f5.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hHDPAUgLu-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training f_5 Model\n",
        "\n",
        "%%time\n",
        "now = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor=\"val_loss\", verbose=1, patience=2),\n",
        "    ModelCheckpoint(\n",
        "        PATH_CHECKPOINTS + now + \"_Model_FT-Embed_{epoch:02d}_{val_loss:.4f}.h5\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "        verbose=1,\n",
        "    ),\n",
        "]\n",
        "\n",
        "#Fitting the model\n",
        "steps_per_epoch = int(np.floor((len(X_train_vec) / BATCH_SIZE)))\n",
        "print(\n",
        "    f\"Model Params.\\nbatch_size: {BATCH_SIZE}\\nEpochs: {EPOCHS}\\n\"\n",
        "    f\"Step p. Epoch: {steps_per_epoch}\\n\"\n",
        ")\n",
        "\n",
        "hist = model_f5.fit(\n",
        "    X_train_vec,\n",
        "    Y_train_f5,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(X_test_vec, Y_test_f5),\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHYqyciBOm-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluation f_5\n",
        "pred = model_f5.predict(X_train_vec)\n",
        "print('Accuracy of f_5 model on Training set')\n",
        "print(accuracy_score(Y_train_f5.argmax(axis=1), pred.argmax(axis=1)))\n",
        "print()\n",
        "\n",
        "# Predict on test data\n",
        "pred = model_f5.predict(X_test_vec)\n",
        "\n",
        "# Show prediction metrics\n",
        "print('Accuracy of f_5 model on Test set')\n",
        "print(accuracy_score(Y_test_f5.argmax(axis=1), pred.argmax(axis=1)))\n",
        "print()\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(Y_test_f5.argmax(axis=1), pred.argmax(axis=1)))\n",
        "print()\n",
        "print('Classification Report')\n",
        "report = metrics.classification_report(Y_test_f5.argmax(axis=1), pred.argmax(axis=1))\n",
        "print(report)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH-uBYRVMjcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the model\n",
        "model_f5.save('/content/drive/My Drive/Data/LSTM/saved models/cognitiveempathy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CGzfVpWPzKM",
        "colab_type": "text"
      },
      "source": [
        "# Loading models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL0Mg7Q9PJro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading f_4\n",
        "model_f4=tf.keras.models.load_model('/content/drive/My Drive/Data/LSTM/saved models/emotionalempathy')\n",
        "model_f4.summary()\n",
        "\n",
        "#Predicting\n",
        "pred = model_f4.predict(X_test_vec)\n",
        "\n",
        "print('Accuracy of f_4 model on Test set')\n",
        "print(accuracy_score(Y_test_f4.argmax(axis=1), pred.argmax(axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDvkCyaOP5yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading f_5\n",
        "model_f5=tf.keras.models.load_model('/content/drive/My Drive/Data/LSTM/saved models/cognitiveempathy')\n",
        "model_f5.summary()\n",
        "\n",
        "#Predicting\n",
        "pred = model_f5.predict(X_test_vec)\n",
        "\n",
        "print('Accuracy of f_5 model on Test set')\n",
        "print(accuracy_score(Y_test_f5.argmax(axis=1), pred.argmax(axis=1)))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}