{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FARM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xTdVaFz6g9QG"
      ],
      "toc_visible": true,
      "mount_file_id": "1mrA8tTwgNZs-rh55EVOJx-plbDa0JZ6f",
      "authorship_tag": "ABX9TyMsqg5E1hyHl92L8Jh0lAfn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5Gzc7uL2LpL",
        "colab_type": "text"
      },
      "source": [
        "# **FARM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFrAzQDq-mho",
        "colab_type": "text"
      },
      "source": [
        "Set-Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD1DoqCNZ80Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#installing FARM\n",
        "!git clone https://github.com/deepset-ai/FARM.git\n",
        "!pip install -r FARM/requirements.txt\n",
        "!pip install FARM/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TsfVs1aaGjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing modules\n",
        "import torch\n",
        "from farm.modeling.tokenization import Tokenizer\n",
        "from farm.data_handler.processor import TextClassificationProcessor\n",
        "from farm.data_handler.data_silo import DataSilo\n",
        "from farm.modeling.language_model import LanguageModel\n",
        "from farm.modeling.prediction_head import MultiLabelTextClassificationHead\n",
        "from farm.modeling.adaptive_model import AdaptiveModel\n",
        "from farm.modeling.optimization import initialize_optimizer\n",
        "from farm.infer import Inferencer\n",
        "from farm.train import Trainer\n",
        "from farm.utils import MLFlowLogger, initialize_device_settings, set_all_seeds, MLFlowLogger\n",
        "import logging\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Urbb73jCk-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tracking the results\n",
        "#ml_logger = MLFlowLogger(tracking_uri=\"https://public-mlflow.deepset.ai/\")\n",
        "#ml_logger.init_experiment(experiment_name=\"Empathy\", run_name=\"final\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8AB1u4VbHYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fetch the right device \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Devices available: {}\".format(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17iRm6u_EPe6",
        "colab_type": "text"
      },
      "source": [
        "Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-pr9ISTdwRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initializing parameters \n",
        "set_all_seeds(seed=42)\n",
        "device, n_gpu = initialize_device_settings(use_cuda=True)\n",
        "n_epochs = 3\n",
        "learning_rate = 3e-5\n",
        "embeds_dropout_prob = 0.1\n",
        "batch_size = 8\n",
        "evaluate_every = 100\n",
        "\n",
        "lang_model = \"bert-base-german-cased\"\n",
        "do_lower_case = False \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKXUwUOJni1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the dataset\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Data/dataset_groupedempathylevel.csv\")\n",
        "df.drop(df[df['length']<=3].index, inplace = True)  #droping all rows that are smaller/equal 3 in length\n",
        "columns_to_keep = ['text','classID', 'f_4', 'f_5'] #dropping the rest\n",
        "df = df[columns_to_keep]\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvIjgxMMWyHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting the dataset to train/test\n",
        "from numpy.random import RandomState\n",
        "rng = RandomState()\n",
        "components_train = df.sample(frac=0.8, random_state=42)\n",
        "components_test = df.loc[~df.index.isin(components_train.index)]\n",
        "components_train.to_csv('/content/drive/My Drive/Data/Farm/train.tsv', sep='\\t', index=False, header=True)\n",
        "components_test.to_csv('/content/drive/My Drive/Data/Farm/test.tsv', sep='\\t', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLjP02h9eQwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a tokenizer (here: BERT tokenizer loaded with german model)\n",
        "tokenizer = Tokenizer.load(\n",
        "    pretrained_model_name_or_path=lang_model,\n",
        "    do_lower_case=do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iijbgoPqyBvG",
        "colab_type": "text"
      },
      "source": [
        "# Model Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSJMT0Qayi9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a processor to handle conversion from raw text to PyTorch Dataset\n",
        "label_list = ['strength', \"weakness\", \"suggestions\", \"None\"] #labels in the data set\n",
        "metric = \"f1_macro\"  # desired metric for evaluation\n",
        "\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                            max_seq_len=512, # BERT can only handle sequence lengths of up to 512\n",
        "                                            data_dir='/content/drive/My Drive/Data/Farm', \n",
        "                                            label_list=label_list,\n",
        "                                            label_column_name=\"classID\", \n",
        "                                            metric=metric,\n",
        "                                            quote_char='\"',\n",
        "                                            multilabel=True,\n",
        "                                            train_filename=\"train.tsv\",\n",
        "                                            dev_filename=None,\n",
        "                                            test_filename=\"test.tsv\",\n",
        "                                            dev_split=0.2 # this will extract 20% of the train set to create a dev set\n",
        "                                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-MCHS6ry59i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a DataSilo to load various datasets(train/test/dev)\n",
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvoueAUNy9YR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the pretrained BERT german model\n",
        "language_model = LanguageModel.load(lang_model)\n",
        "\n",
        "#Define a prediction head that fits for text classification with multiple labels\n",
        "prediction_head = MultiLabelTextClassificationHead(class_weights=data_silo.calculate_class_weights(task_name=\"text_classification\"),num_labels=len(label_list))\n",
        "\n",
        "#Create the model\n",
        "model = AdaptiveModel(\n",
        "        language_model=language_model,\n",
        "        prediction_heads=[prediction_head],\n",
        "        embeds_dropout_prob=embeds_dropout_prob,\n",
        "        lm_output_types=[\"per_sequence\"],\n",
        "        device=device)\n",
        "model.fit_heads_to_lm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcwRrG7AzCMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the optimizer\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    learning_rate=learning_rate,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9UOL200zERS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feeding to the Trainer\n",
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        data_silo=data_silo,\n",
        "        epochs=n_epochs,\n",
        "        n_gpu=n_gpu,\n",
        "        lr_schedule=lr_schedule,\n",
        "        evaluate_every=evaluate_every,\n",
        "        device=device)\n",
        "#Training and growing\n",
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drzvARXXzGiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save the model\n",
        "save_dir_components = \"/content/drive/My Drive/Data/Farm/saved_models/components_final\"\n",
        "model.save(save_dir_components)\n",
        "processor.save(save_dir_components)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTdVaFz6g9QG",
        "colab_type": "text"
      },
      "source": [
        "# **Model f_4 (emotional empathy)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LQ0uxAzg_Wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a processor to handle conversion from raw text to PyTorch Dataset\n",
        "label_list = ['non-empathic', 'empathic', \"neutral\", \"None\"] #labels in the data set\n",
        "metric = \"f1_macro\"  # desired metric for evaluation\n",
        "\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                            max_seq_len=512, # BERT can only handle sequence lengths of up to 512\n",
        "                                            data_dir='/content/drive/My Drive/Data/Farm', \n",
        "                                            label_list=label_list,\n",
        "                                            label_column_name=\"f_4\", \n",
        "                                            metric=metric,\n",
        "                                            quote_char='\"',\n",
        "                                            multilabel=True,\n",
        "                                            train_filename=\"train.tsv\",\n",
        "                                            dev_filename=None,\n",
        "                                            test_filename=\"test.tsv\",\n",
        "                                            dev_split=0.2 # this will extract 20% of the train set to create a dev set\n",
        "                                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s2sR_aKhSVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a DataSilo to load various datasets(train/test/dev)\n",
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgDdVhfDhV0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the pretrained BERT german model\n",
        "language_model = LanguageModel.load(lang_model)\n",
        "\n",
        "#Define a prediction head that fits for text classification with multiple labels\n",
        "prediction_head = MultiLabelTextClassificationHead(class_weights=data_silo.calculate_class_weights(task_name=\"text_classification\"),num_labels=len(label_list))\n",
        "\n",
        "#Create the model\n",
        "model = AdaptiveModel(\n",
        "        language_model=language_model,\n",
        "        prediction_heads=[prediction_head],\n",
        "        embeds_dropout_prob=embeds_dropout_prob,\n",
        "        lm_output_types=[\"per_sequence\"],\n",
        "        device=device)\n",
        "model.fit_heads_to_lm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L3sekDrhYbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the optimizer\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    learning_rate=learning_rate,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNgI2dnaiRnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feeding to the Trainer\n",
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        data_silo=data_silo,\n",
        "        epochs=n_epochs,\n",
        "        n_gpu=n_gpu,\n",
        "        lr_schedule=lr_schedule,\n",
        "        evaluate_every=evaluate_every,\n",
        "        device=device)\n",
        "#Training and growing\n",
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtUm2Qq3hbGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save the model\n",
        "save_dir_f4 = \"/content/drive/My Drive/Data/Farm/saved_models/emotionalempathy_final\"\n",
        "model.save(save_dir_f4)\n",
        "processor.save(save_dir_f4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuJvwa2qgmJ6",
        "colab_type": "text"
      },
      "source": [
        "# **Model f_5 (cognitive empathy)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfSJM29abVGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a processor to handle conversion from raw text to PyTorch Dataset\n",
        "label_list = ['non-empathic', 'empathic', \"neutral\", \"None\"] #labels in the data set\n",
        "metric = \"f1_macro\"  # desired metric for evaluation\n",
        "\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                            max_seq_len=512, # BERT can only handle sequence lengths of up to 512\n",
        "                                            data_dir='/content/drive/My Drive/Data/Farm', \n",
        "                                            label_list=label_list,\n",
        "                                            label_column_name=\"f_5\", \n",
        "                                            metric=metric,\n",
        "                                            quote_char='\"',\n",
        "                                            multilabel=True,\n",
        "                                            train_filename=\"train.tsv\",\n",
        "                                            dev_filename=None,\n",
        "                                            test_filename=\"test.tsv\",\n",
        "                                            dev_split=0.2 # this will extract 20% of the train set to create a dev set\n",
        "                                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qib6WMeVbgVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a DataSilo to load various datasets(train/test/dev)\n",
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7B4h7O8fTA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the pretrained BERT german model\n",
        "language_model = LanguageModel.load(lang_model)\n",
        "\n",
        "#Define a prediction head that fits for text classification with multiple labels\n",
        "prediction_head = MultiLabelTextClassificationHead(class_weights=data_silo.calculate_class_weights(task_name=\"text_classification\"), num_labels=len(label_list))\n",
        "\n",
        "#Create the model\n",
        "model = AdaptiveModel(\n",
        "        language_model=language_model,\n",
        "        prediction_heads=[prediction_head],\n",
        "        embeds_dropout_prob=embeds_dropout_prob,\n",
        "        lm_output_types=[\"per_sequence\"],\n",
        "        device=device)\n",
        "model.fit_heads_to_lm()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1d76sDmv3cJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the optimizer\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    learning_rate=learning_rate,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGs09Zf4wCJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feeding to the Trainer\n",
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        data_silo=data_silo,\n",
        "        epochs=n_epochs,\n",
        "        n_gpu=n_gpu,\n",
        "        lr_schedule=lr_schedule,\n",
        "        evaluate_every=evaluate_every,\n",
        "        device=device)\n",
        "#Training and growing\n",
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD_0vKeRwSdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save the model\n",
        "save_dir_f5 = \"/content/drive/My Drive/Data/Farm/saved_models/cognitiveempathy_final\"\n",
        "model.save(save_dir_f5)\n",
        "processor.save(save_dir_f5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpnip_BUx26g",
        "colab_type": "text"
      },
      "source": [
        "# Test on Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kj3BMARKZqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test the model on a sample \n",
        "from farm.infer import Inferencer\n",
        "from pprint import PrettyPrinter\n",
        "\n",
        "\n",
        "basic_texts = [{\"text\": \"Das Template wurde gut umgesetzt. Die Darstellung ist schlüssig, Persona und User Cycle passen zusammen.\"\n",
        "}]\n",
        "#inferenced_model = Inferencer.load(\"/content/drive/My Drive/Data/Farm/saved_models/components_final\")\n",
        "inferenced_model= Inferencer.load(\"/content/drive/My Drive/Data/Farm/saved_models/cognitiveempathy_final\")\n",
        "#inferenced_model= Inferencer.load(\"/content/drive/My Drive/Data/Farm/saved_models/emotionalempathy_final\")\n",
        "result = inferenced_model.inference_from_dicts(dicts=basic_texts)\n",
        "PrettyPrinter().pprint(result)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcAbbf5jbuMv",
        "colab_type": "text"
      },
      "source": [
        "Codes based on https://deepset.ai/german-bert"
      ]
    }
  ]
}